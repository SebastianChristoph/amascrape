import logging
from datetime import datetime, timezone
from sqlalchemy.orm import Session
from app.database import SessionLocal
from app.models import Market, MarketChange, MarketCluster, Product, ProductChange
from scraper.first_page_amazon_scraper import AmazonFirstPageScraper

# Logging einrichten
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

class Market_Orchestrator:
    def __init__(self):
        pass

    def get_latest_market_change(self, db: Session, market_id: int):
        """ ğŸ·ï¸ Holt den letzten MarketChange fÃ¼r einen Markt """
        logging.info(f"ğŸ“¢ Suche letzten MarketChange fÃ¼r Market-ID {market_id}...")
        return db.query(MarketChange).filter(MarketChange.market_id == market_id).order_by(MarketChange.change_date.desc()).first()

    def fetch_current_market_data(self, keyword: str):
        """ ğŸ” Holt aktuelle Marktdaten von Amazon """
        logging.info(f"ğŸš€ Starte Scraping fÃ¼r Markt: {keyword}")
        scraper = AmazonFirstPageScraper(headless=True, show_details=True)
        return scraper.get_first_page_data(keyword)

    def calculate_total_revenue(self, db: Session, market: Market, last_market_change: MarketChange):
        """ ğŸ’° Berechnet total_revenue fÃ¼r einen Markt basierend auf den letzten validen Produkt-Daten """
        logging.info(f"ğŸ’° Berechne Total Revenue fÃ¼r {market.keyword}...")

        total_revenue = 0
        today = datetime.now(timezone.utc).date()
        has_valid_products = False  # PrÃ¼ft, ob es wenigstens ein Produkt mit alten Scrape-Daten gibt

        for product in market.products:
            # 1ï¸âƒ£ Finde den letzten ProductChange, der **NICHT** von heute ist
            last_valid_product_change = db.query(ProductChange) \
                .filter(ProductChange.asin == product.asin, ProductChange.change_date < today) \
                .order_by(ProductChange.change_date.desc()) \
                .first()

            if last_valid_product_change and last_valid_product_change.total is not None:
                logging.info(f"âœ… Produkt {product.asin} trÃ¤gt {last_valid_product_change.total:.2f}â‚¬ zum Revenue bei. (Letzter Scrape: {last_valid_product_change.change_date.date()})")
                total_revenue += last_valid_product_change.total
                has_valid_products = True  # Es gibt gÃ¼ltige Umsatzdaten
            else:
                logging.warning(f"âš ï¸ Kein Ã¤lterer ProductChange fÃ¼r {product.asin} gefunden. Umsatz nicht berÃ¼cksichtigt!")

        # 2ï¸âƒ£ Falls KEIN einziges Produkt eine gÃ¼ltige alte Umsatzberechnung hat
        if not has_valid_products:
            if last_market_change and last_market_change.total_revenue is not None:
                total_revenue = last_market_change.total_revenue
                logging.warning(f"âš ï¸ Kein einziges Produkt hat alte Umsatzdaten! Ãœbernehme alten MarketChange Revenue: {total_revenue:.2f}â‚¬")
            else:
                logging.warning(f"âŒ Kein Ã¤lterer MarketChange Revenue vorhanden! Setze total_revenue auf None.")
                total_revenue = None  # Wichtige Ã„nderung!

        logging.info(f"ğŸ·ï¸ Gesamtumsatz fÃ¼r {market.keyword}: {total_revenue if total_revenue is not None else 'None'}â‚¬")
        return total_revenue


    def detect_changes(self, last_market_change, new_data):
        """ ğŸ”„ Vergleicht alte und neue Marktdaten und ermittelt Ã„nderungen """
        logging.info(f"ğŸ” Vergleiche alte und neue Daten fÃ¼r MarketChange ID {last_market_change.id}")

        added_asins = []
        removed_asins = []
        new_suggestions = []

        old_asins = set(last_market_change.new_products.split(",")) if last_market_change.new_products else set()
        new_asins = set(p["asin"] for p in new_data["first_page_products"])

        added_asins = list(new_asins - old_asins)
        removed_asins = list(old_asins - new_asins)

        old_suggestions = set(last_market_change.top_suggestions.split(",")) if last_market_change.top_suggestions else set()
        new_suggestions = set(new_data["top_search_suggestions"])

        changes = []
        if added_asins:
            logging.info(f"âœ… Neue Produkte gefunden: {', '.join(added_asins)}")
            changes.append(f"Neue Produkte: {', '.join(added_asins)}")
        if removed_asins:
            logging.info(f"âš ï¸ Entfernte Produkte: {', '.join(removed_asins)}")
            changes.append(f"Entfernte Produkte: {', '.join(removed_asins)}")
        if old_suggestions != new_suggestions:
            logging.info(f"âš ï¸ Ã„nderungen in den Top-SuchvorschlÃ¤gen erkannt!")
            changes.append("Ã„nderungen in den Top-SuchvorschlÃ¤gen")

        return changes, added_asins, removed_asins, list(new_suggestions)

    def update_market_changes(self, db: Session, market: Market, new_market_change: MarketChange, new_data, added_asins, removed_asins):
        """ ğŸ”„ Aktualisiert MarketChange mit neuen Produkten und Ã„nderungen """
        logging.info(f"ğŸ“¢ Aktualisiere MarketChange fÃ¼r {market.keyword}...")

        new_market_change.new_products = ",".join(added_asins)
        new_market_change.removed_products = ",".join(removed_asins)
        new_market_change.top_suggestions = ",".join(new_data["top_search_suggestions"])

        # Neue Produkte hinzufÃ¼gen
        for product_data in new_data["first_page_products"]:
            product = db.query(Product).filter(Product.asin == product_data["asin"]).first()
            if not product:
                logging.info(f"ğŸ†• Neues Produkt {product_data['asin']} wird erstellt.")
                product = Product(asin=product_data["asin"], last_time_scraped=None)
                db.add(product)
                db.commit()
                db.refresh(product)

            if product not in market.products:
                market.products.append(product)
            if product not in new_market_change.products:
                new_market_change.products.append(product)

        # Entfernte Produkte aus Market entfernen
        if removed_asins:
            removed_products = db.query(Product).filter(Product.asin.in_(removed_asins)).all()
            for product in removed_products:
                if product in market.products:
                    market.products.remove(product)
                if product in new_market_change.products:
                    new_market_change.products.remove(product)

        db.commit()
        logging.info(f"âœ… MarketChange fÃ¼r {market.keyword} aktualisiert.")

    def update_market_cluster_total_revenue(self):
        """ ğŸ”„ Aktualisiert total_revenue fÃ¼r alle MarketCluster """
        db = SessionLocal()
        try:
            logging.info("ğŸ“¢ Aktualisiere total_revenue fÃ¼r alle MarketCluster...")

            clusters = db.query(MarketCluster).all()
            for cluster in clusters:
                total_revenue = sum(
                    self.get_latest_market_change(db, market.id).total_revenue or 0 for market in cluster.markets
                )
                cluster.total_revenue = total_revenue
                db.commit()
                logging.info(f"âœ… Aktualisiertes Revenue fÃ¼r Cluster '{cluster.title}': {total_revenue}")

        except Exception as e:
            db.rollback()
            logging.error(f"âŒ Fehler beim Update des total_revenue fÃ¼r MarketCluster: {e}")
        finally:
            db.close()

    def update_market_revenue_and_changes(self):
        """ ğŸš€ FÃ¼hrt Market-Update durch, berechnet Revenue und prÃ¼ft Ã„nderungen """
        db = SessionLocal()
        try:
            logging.info("ğŸš€ Starte Market-Revenue-Berechnung und Updates...")

            markets = db.query(Market).all()
            for market in markets:
                logging.info(f"\nğŸ” Starte Update fÃ¼r Markt: {market.keyword}")

                last_market_change = self.get_latest_market_change(db, market.id)
                if not last_market_change:
                    logging.warning(f"âš ï¸ Kein MarketChange fÃ¼r {market.keyword} gefunden! Ãœberspringe...")
                    continue  

                scraped_products = [p for p in market.products if p.last_time_scraped is not None]
                if not scraped_products:
                    logging.info(f"âš ï¸ Noch keine Scraping-Daten fÃ¼r {market.keyword}. Warte auf Product Orchestrator.")
                    continue  

                # âœ… FIX: Hier wird last_market_change als Parameter Ã¼bergeben
                new_total_revenue = self.calculate_total_revenue(db, market, last_market_change)

                new_data = self.fetch_current_market_data(market.keyword)
                if not new_data:
                    logging.warning(f"âŒ Keine neuen Daten fÃ¼r {market.keyword}, Ã¼berspringe...")
                    continue  

                changes, added_asins, removed_asins, new_suggestions = self.detect_changes(last_market_change, new_data)

                if new_total_revenue != last_market_change.total_revenue or changes:
                    logging.info(f"âš¡ Erstelle neuen MarketChange fÃ¼r {market.keyword}")

                    new_market_change = MarketChange(
                        market_id=market.id,
                        change_date=datetime.now(timezone.utc),
                        total_revenue=new_total_revenue,
                        new_products=",".join(added_asins),
                        removed_products=",".join(removed_asins),
                        top_suggestions=",".join(new_suggestions),
                        changes=" | ".join(changes) if changes else "Kein Total Revenue Change, aber andere Ã„nderungen"
                    )
                    db.add(new_market_change)
                    db.commit()
                    db.refresh(new_market_change)

                    self.update_market_changes(db, market, new_market_change, new_data, added_asins, removed_asins)
                else:
                    logging.info(f"âœ… Keine Ã„nderungen fÃ¼r {market.keyword}, MarketChange bleibt unverÃ¤ndert.")

            self.update_market_cluster_total_revenue()
        except Exception as e:
            db.rollback()
            logging.error(f"âŒ Fehler bei Market-Revenue-Update: {e}")
        finally:
            db.close()




if __name__ == "__main__":
    orchestrator = Market_Orchestrator()
    orchestrator.update_market_revenue_and_changes()
